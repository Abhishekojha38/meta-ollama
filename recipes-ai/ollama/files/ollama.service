[Unit]
Description=Ollama Service - Local Large Language Model Runtime
Documentation=https://github.com/ollama/ollama/tree/main/docs
After=network-online.target
Wants=network-online.target

[Service]
Type=exec
ExecStart=/usr/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_MODELS=/var/lib/ollama/models"

# Security settings
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/ollama

# Resource limits (adjust based on your system)
# For systems with limited RAM, you may want to set MemoryMax
# MemoryMax=8G
# For CPU limits
# CPUQuota=400%

[Install]
WantedBy=multi-user.target
